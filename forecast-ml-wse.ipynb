{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current environment located at: z:\\Python\\smartport\\smartport-master\\.env\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import date, datetime, timedelta\n",
    "import json\n",
    "from shapely.geometry import box, mapping\n",
    "from geocube.api.core import make_geocube\n",
    "from geocube.rasterize import rasterize_points_griddata\n",
    "from functools import partial\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas.io.sql as psql\n",
    "import xarray as xr\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "dotenv_path = Path('.env') # Load environment file\n",
    "load_dotenv(dotenv_path=dotenv_path) # Loads environment variables from .env file inside the project\n",
    "print(f\"Current environment located at: {find_dotenv()}\")\n",
    "\n",
    "path_to_root = Path(os.path.dirname(find_dotenv())) # Path to root of project\n",
    "path_to_wse = Path(path_to_root, \"data\", \"wse\",) # Path to wse data\n",
    "path_to_collateral = Path(path_to_root, \"data\", \"collateral\") # Path to collateral data\n",
    "\n",
    "if not path_to_wse.exists(): # Create directories if they don't exist\n",
    "    path_to_wse.mkdir() # Create wse directory\n",
    "if not path_to_collateral.exists(): # Create directories if they don't exist\n",
    "    path_to_collateral.mkdir() # Create collateral directory\n",
    "\n",
    "assert( path_to_root.exists() ) # Check that path to root exists\n",
    "assert( path_to_wse.exists() ) # Check that path to wse exists\n",
    "assert( path_to_collateral.exists() ) # Check that path to collateral exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some default time variables for reference\n",
    "today = date.today(); current = today - timedelta(days = 1); yesterday = today - timedelta(days =2) # Set today, current, and yesterday variables\n",
    "\n",
    "def wse_preprocess(\n",
    "                min_date: str, # Defines min_date variable, needs to be passed in %Y-%m-%d format\n",
    "                max_date: str, # Defines max_date variable, needs to be passed in %Y-%m-%d format\n",
    "                resolution: int, # Defines resolution variable\n",
    "                dbname: str = os.environ.get(\"POSTGRES_DATABASE\"),  # Defines database name variable by retrieving value from environment variable\n",
    "                user_db: str = os.environ.get(\"POSTGRES_USER\"), # Defines user variable by retrieving value from environment variable\n",
    "                password: str = os.environ.get(\"POSTGRES_PASSWORD\"), # Defines password variable by retrieving value from environment variable\n",
    "                port: str = os.environ.get(\"POSTGRES_PORT\"), # Defines port variable by retrieving value from environment variable\n",
    "                host: str = os.environ.get(\"POSTGRES_HOST\"), # Defines host variable by retrieving value from environment variable\n",
    "                ) -> tuple:\n",
    "    \"\"\"Retrieves water surface elevation data from PostgreSQL database and generates list of time steps and dictionary of time ranges.\"\"\"\n",
    "\n",
    "    #Set time query\n",
    "    start = (pd.Timestamp(min_date) - timedelta(days = 1)).strftime('%Y-%m-%d') # Sets start variable as min_date - 3 hours\n",
    "    end = (pd.Timestamp(max_date) + timedelta(days = 2)).strftime('%Y-%m-%d') # Converts max_date from datetime object to a string\n",
    "\n",
    "    # Create connection\n",
    "    engine = create_engine(f\"postgresql://{user_db}:{password}@{host}:{port}/{dbname}\") # Creates an engine connection with PostgreSQL using the variables above\n",
    "\n",
    "    # Retrieves data from rg_wse_3h_subset between min_date and max_date \n",
    "    sql = f\"SELECT * FROM rg_wse_silver_3h_subset WHERE time<'{end}'and time>'{start}'\"# and sid in ('rg_01120','rg_01220')\" # Second condition filtera data to specific stations \n",
    "    wse_df = psql.read_sql(sql, engine) # Executes SQL query and stores result as dataframe\n",
    "    wse_df_types = wse_df.dtypes # Gets data types of columns in dataframe\n",
    "    wse_df = wse_df.rename(columns={'long_g':'lon_g'}).sort_values('time').reset_index(drop=True) # Sorts values in dataframe by time column\n",
    "\n",
    "    #Create list of time steps\n",
    "    wse_period_range = wse_df['time'].drop_duplicates().values.tolist() # Generates list of unique time values from dataframe\n",
    "\n",
    "    #Convert POSIX time to datetime then string\n",
    "    def format_time(time): # Defines function to convert POSIX time to datetime/string format\n",
    "        format = pd.to_datetime(time) # Converts POSIX time to datetime type\n",
    "        return format.strftime('%Y-%m-%d %H:%M:%S') # Converts datetime type to string\n",
    "\n",
    "    # Format time variable as datetime dtype and drop unnecessary timesteps\n",
    "    wse_period_list = list((map(lambda t: format_time(t), wse_period_range))) # Generates list of strings from datetime objects\n",
    "    wse_period_list = wse_period_list[6:-7] # Removes first 6 and last 7 timesteps from list\n",
    "\n",
    "    # Collapse start and end time to generate dictionary of time ranges\n",
    "    period_start = pd.Timestamp(start) + timedelta(days = 1) # Sets period_start variable as start date + 1 day\n",
    "    period_end = pd.Timestamp(end) - timedelta(days = 2) # Sets period_end variable as end date - 2 days\n",
    "    \n",
    "    # Create dictionary of time ranges\n",
    "    day_list = [] # Initialize day_list variable as empty list\n",
    "    period_dict = {} # Initialize period_dict variable as empty dictionary\n",
    "    day_range = pd.date_range(start=period_start, end=period_end, freq=\"D\") # Generates list of days between period_start and period_end\n",
    "\n",
    "    for d in day_range: # Loops over day_range\n",
    "        day_list.append('y' + d.strftime('%Y') + '_d' + d.strftime('%j')) # Appends day_list with string of year and day of year\n",
    "        previous_step = d - timedelta(hours = 3) # Sets previous_step variable as d - 3 hours\n",
    "        next_step = d + timedelta(days = 1) # Sets next_step variable as d + 1 day\n",
    "        period_dict[d.strftime('y%Y_d%j')] = [] # Sets key as string of year and day of year and value as empty list\n",
    "        range = pd.date_range(start=previous_step, end=next_step, freq='3H') # Generates list of hours between previous_step and next_step\n",
    "        for t in range: # Loops over range\n",
    "            stamp = t.strftime('%Y%m%dT%H%M') # Sets stamp variable as string of year, month, day, hour, and minute\n",
    "            day = t.strftime('%j') # Sets day variable as string of day of year\n",
    "            filename_template = \"wse_{resolution}m_{stamp}_y{t.year}_d{day}.nc\" # Sets filename_template variable as string with resolution, stamp, year, and day\n",
    "            ind_period = filename_template.format(resolution=resolution, stamp=stamp, t=t, day=day) # Sets ind_period variable as filename_template with resolution, stamp, t, and day\n",
    "            filename = path_to_wse.joinpath(ind_period) # Sets filename variable as path_to_wse joined with ind_period\n",
    "            abs_path = str(filename.absolute()) # Sets abs_path variable as string of absolute path of filename\n",
    "            period_dict[d.strftime('y%Y_d%j')].append(abs_path) # Appends period_dict with key and value\n",
    "            \n",
    "    return resolution, wse_df, wse_period_list, day_list, period_dict\n",
    "\n",
    "def wse_interp(\n",
    "            time_query: datetime, \n",
    "            resolution: int,\n",
    "            wse_df: pd.DataFrame,\n",
    "                ) -> None:\n",
    "    \"\"\"Interpolates water surface elevation data to a regular grid and exports as .netcdf file.\"\"\"\n",
    "        \n",
    "    # Pass period selection to create subset dataframe \n",
    "    period_select = str(time_query) # Convert time_query to string\n",
    "    wse_slice_df = wse_df.loc[wse_df['time'] == period_select] # Create subset dataframe of WSE values for selected period\n",
    "    \n",
    "    # Remove gage at Cape Giradeau to fix conflict with river mile join\n",
    "    bad_gage = 'rg_CE401278' # Define gage to be removed\n",
    "    wse_slice_df = wse_slice_df.loc[wse_slice_df['sid'] != bad_gage] # Remove gage from subset dataframe\n",
    "    \n",
    "    # Import river mile .geojson into gdf and drop matching columns to simplify following join\n",
    "    url = 'https://raw.githubusercontent.com/hbienn/smartport_wse/main/'; rm_formatted = f'{url}/mr_rm_banks.geojson' # Define url for river mile .geojson\n",
    "    rm_gdf = gpd.read_file(rm_formatted, crs='epsg:4326') # Import river mile .geojson into gdf\n",
    "    rm_gdf = rm_gdf.drop(columns=['OBJECTID', 'ord', 'sid', 'wse', 'time', 'lat_g', 'lon_g', 'bank']) # Drop matching columns to simplify following join\n",
    "    \n",
    "    # Round river mile to 1 decimal place to account for any floating precision errors\n",
    "    rm_gdf = rm_gdf.round({'mile':1}).sort_values('mile').reindex() # Round river mile to 1 decimal place then sort and reindex\n",
    "    \n",
    "    # Merge WSE df with river mile gdf using mile as key\n",
    "    wse_gdf = rm_gdf.merge(wse_slice_df, how='outer', on='mile') # Merge WSE df with river mile gdf using mile as key\n",
    "    cols = wse_gdf.columns.tolist() # Create list of column names\n",
    "    cols = ['mile', 'sid', 'z', 'time','lon', 'lat', 'lat_g', 'lon_g', 'geometry'] # Reorder column names\n",
    "    wse_gdf = wse_gdf[cols].sort_values('mile') # Reassign column names to gdf and sort values by river mile\n",
    "    \n",
    "    # Establishes a time dimension for each point that is persistent through the downstream interpolation.\n",
    "    period = pd.to_datetime(time_query); year = period.strftime(\"%Y\"); day = period.strftime(\"%j\") # Extract year and day of year from time_query\n",
    "    period = int(round(period.timestamp())*1000000000) # Convert POSIX time to integer\n",
    "    wse_gdf.insert(4,'period', period) # Insert period column into gdf\n",
    "    \n",
    "    # Interpolate missing WSE values\n",
    "    wse_gdf = wse_gdf.loc[wse_gdf['mile'] <= 1000] # Subset gdf to limit spatial domain to south of RM 1000 in the vicinity of Cape Giradeau, MO\n",
    "    #wse_gdf = wse_gdf.dissolve(by='mile', aggfunc='mean')\n",
    "    wse_gdf = wse_gdf.sort_values('mile') # Sort values by river mile\n",
    "    wse_gdf['z'] = wse_gdf['z'].interpolate(method='linear', limit_direction = 'both') # Interpolate missing WSE values based on a linear relationship between river mile and known WSE values.\n",
    "    \n",
    "    # User modified variables\n",
    "    bounding_box = json.dumps(mapping(box(-91.7,28.9,-89,38.8))); projection = 'EPSG:26915'  # Bounding box for Mississippi River and PCS: NAD83 UTM Zone 15N\n",
    "    \n",
    "    # Interpolate WSE values to a regular grid\n",
    "    wse_xr = make_geocube(\n",
    "                        vector_data = wse_gdf,\n",
    "                        measurements = ['z',],\n",
    "                        #datetime_measurements=['period'],\n",
    "                        output_crs = projection,\n",
    "                        resolution = (resolution, resolution),\n",
    "                        geom = bounding_box,\n",
    "                        #interpolate_na_method='linear',\n",
    "                        rasterize_function=partial(rasterize_points_griddata, method='linear', filter_nan = True)\n",
    "                          )\n",
    "    # Expand dimensions and populate with the POSIX time value variable previously assigned \n",
    "    period = int(wse_gdf['period'].mean()) # Calculate mean of POSIX time values\n",
    "    wse_xr = wse_xr.expand_dims('time') # Expand dimensions to incorporate time\n",
    "    arr = wse_xr['time'].to_numpy(); arr[0,] = period # Assign POSIX time value to array\n",
    "    wse_xr['time'] = arr; wse_xr['time'] = pd.to_datetime(wse_xr['time'],utc=True) # Assign POSIX time value to xarray and convert to datetime64[ns] dtype\n",
    "    period_label = pd.to_datetime(time_query).strftime('%Y%m%dT%H%M') # Create period label for filename\n",
    "\n",
    "    # Clip surface to extent of Mississippi River\n",
    "    url = 'https://raw.githubusercontent.com/hbienn/smartport_wse/main/'; mr_formatted = f'{url}/generalized_nhdarea_stlouistogulf_utm.geojson'\n",
    "    mr = gpd.read_file(mr_formatted, crs=projection) # Import Mississippi River .geojson into gdf\n",
    "    wse_xr = wse_xr.rio.clip(mr.geometry, mr.crs, drop=True, invert=False) # Clip surface to extent of Mississippi River\n",
    "    \n",
    "    # Export as .netcdf \n",
    "    filename_template = \"wse_{resolution}m_{stamp}_y{year}_d{day}.nc\" # Make filename template by filling in the required data\n",
    "    ind_period = filename_template.format(resolution=resolution, stamp=period_label, year=year, day=day) # Execute format on the filename_template \n",
    "    filename = path_to_wse.joinpath(ind_period) # Join path to output directory with filename\n",
    "    abs_path = str(filename.absolute()) # Convert path to string\n",
    "    wse_xr.to_netcdf(filename) # Export as .netcdf\n",
    "        \n",
    "    return None\n",
    "\n",
    "def wse(\n",
    "        min_date: str = yesterday.strftime('%Y-%m-%d'), # Defines min_date variable, defaults as yesterday's date (with respect to data availability ~ 24 hours lag)\n",
    "        max_date: str = current.strftime('%Y-%m-%d'), # Defines max_date variable, defaults as current date (with respect to data availability ~ 24 hours lag) \n",
    "        resolution: int = 500, # Defines resolution variable, defaults as 500\n",
    "            ) -> None:\n",
    "    \"\"\"Runs wse_interp function using output from wse_preprocess function.\"\"\"\n",
    "    \n",
    "    # Call wse_preprocess to preprocess the data\n",
    "    resolution, wse_df, wse_period_list, day_list, period_dict = wse_preprocess(min_date = min_date, max_date = max_date, resolution = resolution)\n",
    "    \n",
    "    # Loop over wse_period_list and call wse_interp on each item\n",
    "    for t in wse_period_list: # Loops over wse_period_list\n",
    "        wse_interp(time_query = t, resolution = resolution, wse_df = wse_df) # Run wse_interp function\n",
    "        '''if t != wse_period_list[-1]: # If t is not the last item in wse_period_list\n",
    "            wse_interp(time_query = t, resolution = resolution, wse_df = wse_df) # Run wse_interp function\n",
    "        if t == wse_period_list[-1]: # If t is the last item in wse_period_list\n",
    "            break # Break loop'''\n",
    "    \n",
    "    # Loop over day_list and create a netCDF file for each day\n",
    "    for d in day_list: # Loops over day_list\n",
    "        ds = xr.open_mfdataset(period_dict[d], combine = 'by_coords') # Open multiple files as a single dataset\n",
    "        t = pd.to_datetime(ds['time'].values[2]).strftime('%Y%m%d') # Extract date from time variable\n",
    "        combined_output_name = f'wse_{resolution}m_{t}_combine.nc' # Define output name\n",
    "        combined_filename = path_to_wse.joinpath(combined_output_name) # Join path to output directory with filename\n",
    "        ds.to_netcdf(combined_filename) # Export as .netcdf\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wse(min_date='2023-03-01', max_date='2023-03-07', resolution=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stack-geocube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
